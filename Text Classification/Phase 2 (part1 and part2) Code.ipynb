{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79458674",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c90a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k=cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58d961",
   "metadata": {},
   "source": [
    "### Twitter Stance (Primary Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5033b000",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23227383863080686\n",
      "0.2171305892804264\n",
      "\n",
      "Average Kappa score for annotation_40 is  0.22470221395561663\n",
      "\n",
      "\n",
      "0.23227383863080686\n",
      "0.187885157406965\n",
      "\n",
      "Average Kappa score for annotation_38 is  0.21007949801888592\n",
      "\n",
      "\n",
      "0.2171305892804265\n",
      "0.187885157406965\n",
      "\n",
      "Average Kappa score for annotation_39 is  0.20250787334369574\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df0 = pd.read_csv('twitter_stance/twitter_stance_0.csv') #twitter_stance_0\n",
    "df0[\"label\"]=\"\"  #Adding a column for final label\n",
    "\n",
    "df0['annotation_40'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df0['annotation_38'].fillna('missing', inplace=True)\n",
    "df0['annotation_39'].fillna('missing', inplace=True)\n",
    "\n",
    "x40=k(df0.annotation_40, df0.annotation_38) #annotation_40\n",
    "print (x40)\n",
    "y40=k(df0.annotation_40, df0.annotation_39)\n",
    "print (y40)\n",
    "avg40=(x40+y40)/2\n",
    "print('\\nAverage Kappa score for annotation_40 is ', avg40)\n",
    "print('\\n')\n",
    "\n",
    "x38=k(df0.annotation_38, df0.annotation_40) #annotation_38\n",
    "print (x38)\n",
    "y38=k(df0.annotation_38, df0.annotation_39)\n",
    "print (y38)\n",
    "avg38=(x38+y38)/2\n",
    "print('\\nAverage Kappa score for annotation_38 is ', avg38)\n",
    "print('\\n')\n",
    "\n",
    "x39=k(df0.annotation_39, df0.annotation_40) #annotation_39\n",
    "print (x39)\n",
    "y39=k(df0.annotation_39, df0.annotation_38)\n",
    "print (y39)\n",
    "avg39=(x39+y39)/2\n",
    "print('\\nAverage Kappa score for annotation_39 is ', avg39)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe315c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df0.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg40>=0.2: #Checking if annotator is reliable\n",
    "        if df0.annotation_40[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df0.annotation_40[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df0.annotation_40[i]=='unclear':\n",
    "            uc=uc+1\n",
    "    \n",
    "    if avg38>=0.2: #Checking if annotator is reliable    \n",
    "        if df0.annotation_38[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df0.annotation_38[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df0.annotation_38[i]=='unclear':\n",
    "            uc=uc+1\n",
    "    \n",
    "    if avg39>=0.2: #Checking if annotator is reliable\n",
    "        if df0.annotation_39[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df0.annotation_39[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df0.annotation_39[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    \n",
    "    if pm>am and pm>uc:\n",
    "        df0.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df0.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df0.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df0.label[i]=df0.annotation_40[i] #In case of ties\n",
    "\n",
    "df0=df0.drop(columns=df0.columns.values.tolist()[1:len(df0.columns.values.tolist())-1])\n",
    "df0.to_csv(\"tw_st_0.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8fbb73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text           label\n",
       " 0  As #gbpusd falls below the 1.27 handle amidst ...  pro-mitigation\n",
       " 1  Excellent thread on CDC and CDPH school guidel...  pro-mitigation\n",
       " 2  Put on the breaks. #CovidVaccine  https://t.co...  pro-mitigation\n",
       " 3  I agree, but I think 22 years is a bit to shor...         unclear\n",
       " 4  Anyone who entertains - at all - the possibili...         unclear,\n",
       " (300, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head(),df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1f97d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14287843780278742\n",
      "0.4383600112327998\n",
      "0.31155007149287717\n",
      "\n",
      "Average Kappa score for annotation_48 is  0.29759617350948814\n",
      "\n",
      "\n",
      "0.14287843780278742\n",
      "0.2599901332017759\n",
      "0.19327551511050167\n",
      "\n",
      "Average Kappa score for annotation_45 is  0.19871469537168832\n",
      "\n",
      "\n",
      "0.4383600112327998\n",
      "0.2599901332017759\n",
      "0.34592642980482435\n",
      "\n",
      "Average Kappa score for annotation_46 is  0.34809219141313336\n",
      "\n",
      "\n",
      "0.3115500714928773\n",
      "0.19327551511050156\n",
      "0.34592642980482435\n",
      "\n",
      "Average Kappa score for annotation_47 is  0.28358400546940105\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df1 = pd.read_csv (r'twitter_stance/twitter_stance_1.csv') #twitter_stance_1\n",
    "df1[\"label\"]=\"\"  #Adding a column for final label\n",
    "\n",
    "df1['annotation_48'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df1['annotation_45'].fillna('missing', inplace=True)\n",
    "df1['annotation_46'].fillna('missing', inplace=True)\n",
    "df1['annotation_47'].fillna('missing', inplace=True)\n",
    "\n",
    "x48=k(df1.annotation_48, df1.annotation_45) #annotation_48\n",
    "print (x48)\n",
    "y48=k(df1.annotation_48, df1.annotation_46)\n",
    "print (y48)\n",
    "z48=k(df1.annotation_48, df1.annotation_47)\n",
    "print (z48)\n",
    "avg48=(x48+y48+z48)/3\n",
    "print('\\nAverage Kappa score for annotation_48 is ', avg48)\n",
    "print('\\n')\n",
    "\n",
    "x45=k(df1.annotation_45, df1.annotation_48) #annotation_45\n",
    "print (x45)\n",
    "y45=k(df1.annotation_45, df1.annotation_46)\n",
    "print (y45)\n",
    "z45=k(df1.annotation_45, df1.annotation_47)\n",
    "print (z45)\n",
    "avg45=(x45+y45+z45)/3\n",
    "print('\\nAverage Kappa score for annotation_45 is ', avg45)\n",
    "print('\\n')\n",
    "\n",
    "x46=k(df1.annotation_46, df1.annotation_48) #annotation_46\n",
    "print (x46)\n",
    "y46=k(df1.annotation_46, df1.annotation_45)\n",
    "print (y46)\n",
    "z46=k(df1.annotation_46, df1.annotation_47)\n",
    "print (z46)\n",
    "avg46=(x46+y46+z46)/3\n",
    "print('\\nAverage Kappa score for annotation_46 is ', avg46)\n",
    "print('\\n')\n",
    "\n",
    "x47=k(df1.annotation_47, df1.annotation_48) #annotation_47\n",
    "print (x47)\n",
    "y47=k(df1.annotation_47, df1.annotation_45)\n",
    "print (y47)\n",
    "z47=k(df1.annotation_47, df1.annotation_46)\n",
    "print (z47)\n",
    "avg47=(x47+y47+z47)/3\n",
    "print('\\nAverage Kappa score for annotation_47 is ', avg47)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5c7b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df1.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg48>=0.2: #Checking if annotator is reliable\n",
    "        if df1.annotation_48[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df1.annotation_48[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df1.annotation_48[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg45>=0.2: #Checking if annotator is reliable\n",
    "        if df1.annotation_45[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df1.annotation_45[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df1.annotation_45[i]=='unclear':\n",
    "            uc=uc+1\n",
    "    \n",
    "    if avg46>=0.2: #Checking if annotator is reliable\n",
    "        if df1.annotation_46[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df1.annotation_46[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df1.annotation_46[i]=='unclear':\n",
    "            uc=uc+1\n",
    "    \n",
    "    if avg47>=0.2: #Checking if annotator is reliable\n",
    "        if df1.annotation_47[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df1.annotation_47[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df1.annotation_47[i]=='unclear':\n",
    "            uc=uc+1\n",
    "    \n",
    "    if pm>am and pm>uc:\n",
    "        df1.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df1.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df1.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df1.label[i]=df1.annotation_46[i] #In case of ties\n",
    "\n",
    "df1=df1.drop(columns=df1.columns.values.tolist()[1:len(df1.columns.values.tolist())-1])\n",
    "df1.to_csv(\"tw_st_1.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec52f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text            label\n",
       " 0  Putin ahead of the curve. #CovidVaccine https:...          unclear\n",
       " 1  No #compromise on quality of #COVIDvaccine: CM...  anti-mitigation\n",
       " 2  This goes against CDC guidelines. Vaccinated p...   pro-mitigation\n",
       " 3  #Twitter ;\\n\\n#sputnik \\nRussia state-affiliat...          unclear\n",
       " 4  New CDC school guidelines: No masks required f...          unclear,\n",
       " (300, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(),df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2411c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27848373896187806\n",
      "0.27863407545798946\n",
      "0.17759179526873414\n",
      "\n",
      "Average Kappa score for annotation_64 is  0.24490320322953388\n",
      "\n",
      "\n",
      "0.27848373896187817\n",
      "0.3479632615859216\n",
      "0.27914581489042656\n",
      "\n",
      "Average Kappa score for annotation_61 is  0.3018642718127421\n",
      "\n",
      "\n",
      "0.27863407545798946\n",
      "0.3479632615859216\n",
      "0.18973666441593517\n",
      "\n",
      "Average Kappa score for annotation_62 is  0.27211133381994873\n",
      "\n",
      "\n",
      "0.17759179526873403\n",
      "0.27914581489042656\n",
      "0.18973666441593517\n",
      "\n",
      "Average Kappa score for annotation_63 is  0.21549142485836525\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df2 = pd.read_csv (r'twitter_stance/twitter_stance_2.csv') #twitter_stance_2\n",
    "df2[\"label\"]=\"\" #Adding a column for final label\n",
    "\n",
    "df2['annotation_64'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df2['annotation_61'].fillna('missing', inplace=True)\n",
    "df2['annotation_62'].fillna('missing', inplace=True)\n",
    "df2['annotation_63'].fillna('missing', inplace=True)\n",
    "\n",
    "x64=k(df2.annotation_64, df2.annotation_61) #annotation_64\n",
    "print (x64)\n",
    "y64=k(df2.annotation_64, df2.annotation_62)\n",
    "print (y64)\n",
    "z64=k(df2.annotation_64, df2.annotation_63)\n",
    "print (z64)\n",
    "avg64=(x64+y64+z64)/3\n",
    "print('\\nAverage Kappa score for annotation_64 is ', avg64)\n",
    "print('\\n')\n",
    "\n",
    "x61=k(df2.annotation_61, df2.annotation_64) #annotation_61\n",
    "print (x61)\n",
    "y61=k(df2.annotation_61, df2.annotation_62)\n",
    "print (y61)\n",
    "z61=k(df2.annotation_61, df2.annotation_63)\n",
    "print (z61)\n",
    "avg61=(x61+y61+z61)/3\n",
    "print('\\nAverage Kappa score for annotation_61 is ', avg61)\n",
    "print('\\n')\n",
    "\n",
    "x62=k(df2.annotation_62, df2.annotation_64) #annotation_62\n",
    "print (x62)\n",
    "y62=k(df2.annotation_62, df2.annotation_61)\n",
    "print (y62)\n",
    "z62=k(df2.annotation_62, df2.annotation_63)\n",
    "print (z62)\n",
    "avg62=(x62+y62+z62)/3\n",
    "print('\\nAverage Kappa score for annotation_62 is ', avg62)\n",
    "print('\\n')\n",
    "\n",
    "x63=k(df2.annotation_63, df2.annotation_64) #annotation_63\n",
    "print (x63)\n",
    "y63=k(df2.annotation_63, df2.annotation_61)\n",
    "print (y63)\n",
    "z63=k(df2.annotation_63, df2.annotation_62)\n",
    "print (z63)\n",
    "avg63=(x63+y63+z63)/3\n",
    "print('\\nAverage Kappa score for annotation_63 is ', avg63)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6ba92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df2.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg64>=0.2: #Checking if annotator is reliable\n",
    "        if df2.annotation_64[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df2.annotation_64[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df2.annotation_64[i]=='unclear':\n",
    "            uc=uc+1\n",
    "    \n",
    "    if avg61>=0.2: #Checking if annotator is reliable\n",
    "        if df2.annotation_61[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df2.annotation_61[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df2.annotation_61[i]=='unclear':\n",
    "            uc=uc+1\n",
    "            \n",
    "    if avg62>=0.2: #Checking if annotator is reliable    \n",
    "        if df2.annotation_62[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df2.annotation_62[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df2.annotation_62[i]=='unclear':\n",
    "            uc=uc+1\n",
    "            \n",
    "    if avg63>=0.2: #Checking if annotator is reliable\n",
    "        if df2.annotation_63[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df2.annotation_63[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df2.annotation_63[i]=='unclear':\n",
    "            uc=uc+1\n",
    "    \n",
    "    if pm>am and pm>uc:\n",
    "        df2.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df2.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df2.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df2.label[i]=df2.annotation_61[i] #In case of ties\n",
    "\n",
    "df2=df2.drop(columns=df2.columns.values.tolist()[1:len(df2.columns.values.tolist())-1])\n",
    "df2.to_csv(\"tw_st_2.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fac9567e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abb6f2f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27942765968397765\n",
      "0.3176528669158616\n",
      "\n",
      "Average Kappa score for annotation_56 is  0.2985402632999196\n",
      "\n",
      "\n",
      "0.27942765968397754\n",
      "0.2696195305416569\n",
      "\n",
      "Average Kappa score for annotation_54 is  0.2745235951128172\n",
      "\n",
      "\n",
      "0.3176528669158615\n",
      "0.26961953054165677\n",
      "\n",
      "Average Kappa score for annotation_55 is  0.2936361987287591\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df3 = pd.read_csv (r'twitter_stance/twitter_stance_3.csv') #twitter_stance_3\n",
    "df3[\"label\"]=\"\" #Adding a column for final label\n",
    "\n",
    "df3['annotation_56'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df3['annotation_54'].fillna('missing', inplace=True)\n",
    "df3['annotation_55'].fillna('missing', inplace=True)\n",
    "\n",
    "x56=k(df3.annotation_56, df3.annotation_54) #annotation_56\n",
    "print (x56)\n",
    "y56=k(df3.annotation_56, df3.annotation_55)\n",
    "print (y56)\n",
    "avg56=(x56+y56)/2\n",
    "print('\\nAverage Kappa score for annotation_56 is ', avg56)\n",
    "print('\\n')\n",
    "\n",
    "x54=k(df3.annotation_54, df3.annotation_56) #annotation_54\n",
    "print (x54)\n",
    "y54=k(df3.annotation_54, df3.annotation_55)\n",
    "print (y54)\n",
    "avg54=(x54+y54)/2\n",
    "print('\\nAverage Kappa score for annotation_54 is ', avg54)\n",
    "print('\\n')\n",
    "\n",
    "x55=k(df3.annotation_55, df3.annotation_56) #annotation_55\n",
    "print (x55)\n",
    "y55=k(df3.annotation_55, df3.annotation_54)\n",
    "print (y55)\n",
    "avg55=(x55+y55)/2\n",
    "print('\\nAverage Kappa score for annotation_55 is ', avg55)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e739ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df3.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg56>=0.2: #Checking if annotator is reliable\n",
    "        if df3.annotation_56[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df3.annotation_56[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df3.annotation_56[i]=='unclear':\n",
    "            uc=uc+1\n",
    "            \n",
    "    if avg54>=0.2: #Checking if annotator is reliable    \n",
    "        if df3.annotation_54[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df3.annotation_54[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df3.annotation_54[i]=='unclear':\n",
    "            uc=uc+1\n",
    "        \n",
    "    if avg55>=0.2: #Checking if annotator is reliable    \n",
    "        if df3.annotation_55[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df3.annotation_55[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df3.annotation_55[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if pm>am and pm>uc:\n",
    "        df3.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df3.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df3.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df3.label[i]=df3.annotation_56[i] #In case of ties\n",
    "\n",
    "df3=df3.drop(columns=df3.columns.values.tolist()[1:len(df3.columns.values.tolist())-1])\n",
    "df3.to_csv(\"tw_st_3.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c398cd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The public is deeply skeptical about any #coro...</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hmm what are the CDC guidelines? If you’re vac...</td>\n",
       "      <td>pro-mitigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glad he is deciding to throw a party outdoors,...</td>\n",
       "      <td>pro-mitigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Lewis, are you following the revision of C...</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cdc laid out semi reasonable guidelines bu...</td>\n",
       "      <td>pro-mitigation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           label\n",
       "0  The public is deeply skeptical about any #coro...         unclear\n",
       "1  Hmm what are the CDC guidelines? If you’re vac...  pro-mitigation\n",
       "2  Glad he is deciding to throw a party outdoors,...  pro-mitigation\n",
       "3  Dr. Lewis, are you following the revision of C...         unclear\n",
       "4  The cdc laid out semi reasonable guidelines bu...  pro-mitigation"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e0c4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19500517371402515\n",
      "0.23924030430387833\n",
      "\n",
      "Average Kappa score for annotation_112 is  0.21712273900895174\n",
      "\n",
      "\n",
      "0.19500517371402515\n",
      "0.31911749181885374\n",
      "\n",
      "Average Kappa score for annotation_113 is  0.25706133276643944\n",
      "\n",
      "\n",
      "0.23924030430387833\n",
      "0.3191174918188536\n",
      "\n",
      "Average Kappa score for annotation_115 is  0.279178898061366\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df4 = pd.read_csv (r'twitter_stance/twitter_stance_4.csv') #twitter_stance_4\n",
    "df4[\"label\"]=\"\" #Adding a column for final label\n",
    "\n",
    "df4['annotation_112'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df4['annotation_113'].fillna('missing', inplace=True)\n",
    "df4['annotation_115'].fillna('missing', inplace=True)\n",
    "\n",
    "df4['annotation_115'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "\n",
    "x112=k(df4.annotation_112, df4.annotation_113) #annotation_112\n",
    "print (x112)\n",
    "y112=k(df4.annotation_112, df4.annotation_115)\n",
    "print (y112)\n",
    "avg112=(x112+y112)/2\n",
    "print('\\nAverage Kappa score for annotation_112 is ', avg112)\n",
    "print('\\n')\n",
    "\n",
    "x113=k(df4.annotation_113, df4.annotation_112) #annotation_113\n",
    "print (x113)\n",
    "y113=k(df4.annotation_113, df4.annotation_115)\n",
    "print (y113)\n",
    "avg113=(x113+y113)/2\n",
    "print('\\nAverage Kappa score for annotation_113 is ', avg113)\n",
    "print('\\n')\n",
    "\n",
    "x115=k(df4.annotation_115, df4.annotation_112) #annotation_115\n",
    "print (x115)\n",
    "y115=k(df4.annotation_115, df4.annotation_113)\n",
    "print (y115)\n",
    "avg115=(x115+y115)/2\n",
    "print('\\nAverage Kappa score for annotation_115 is ', avg115)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1812c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df4.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg112>=0.2: #Checking if annotator is reliable\n",
    "        if df4.annotation_112[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df4.annotation_112[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df4.annotation_112[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg113>=0.2: #Checking if annotator is reliable\n",
    "        if df4.annotation_113[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df4.annotation_113[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df4.annotation_113[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg115>=0.2: #Checking if annotator is reliable\n",
    "        if df4.annotation_115[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df4.annotation_115[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df4.annotation_115[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if pm>am and pm>uc:\n",
    "        df4.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df4.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df4.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df4.label[i]=df4.annotation_115[i] #In case of ties\n",
    "\n",
    "df4=df4.drop(columns=df4.columns.values.tolist()[1:len(df4.columns.values.tolist())-1])\n",
    "df4.to_csv(\"tw_st_4.csv\", mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c949961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "504f1275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1580432737535279\n",
      "0.12136517139356262\n",
      "\n",
      "Average Kappa score for annotation_75 is  0.13970422257354526\n",
      "\n",
      "\n",
      "0.15804327375352778\n",
      "0.19788828337874664\n",
      "\n",
      "Average Kappa score for annotation_69 is  0.1779657785661372\n",
      "\n",
      "\n",
      "0.12136517139356262\n",
      "0.19788828337874664\n",
      "\n",
      "Average Kappa score for annotation_70 is  0.15962672738615463\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df5 = pd.read_csv (r'twitter_stance/twitter_stance_5.csv') #twitter_stance_5\n",
    "df5[\"label\"]=\"\" #Adding a column for final label\n",
    "\n",
    "df5['annotation_75'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df5['annotation_69'].fillna('missing', inplace=True)\n",
    "df5['annotation_70'].fillna('missing', inplace=True)\n",
    "\n",
    "df5['annotation_70'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "\n",
    "x75=k(df5.annotation_75, df5.annotation_69) #annotation_75\n",
    "print (x75)\n",
    "y75=k(df5.annotation_75, df5.annotation_70)\n",
    "print (y75)\n",
    "avg75=(x75+y75)/2\n",
    "print('\\nAverage Kappa score for annotation_75 is ', avg75)\n",
    "print('\\n')\n",
    "\n",
    "x69=k(df5.annotation_69, df5.annotation_75) #annotation_69\n",
    "print (x69)\n",
    "y69=k(df5.annotation_69, df5.annotation_70)\n",
    "print (y69)\n",
    "avg69=(x69+y69)/2\n",
    "print('\\nAverage Kappa score for annotation_69 is ', avg69)\n",
    "print('\\n')\n",
    "\n",
    "x70=k(df5.annotation_70, df5.annotation_75) #annotation_70\n",
    "print (x70)\n",
    "y70=k(df5.annotation_70, df5.annotation_69)\n",
    "print (y70)\n",
    "avg70=(x70+y70)/2\n",
    "print('\\nAverage Kappa score for annotation_70 is ', avg70)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f63a0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df5.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg75>=0.2: #Checking if annotator is reliable\n",
    "        if df5.annotation_75[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df5.annotation_75[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df5.annotation_75[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg69>=0.2: #Checking if annotator is reliable\n",
    "        if df5.annotation_69[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df5.annotation_69[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df5.annotation_69[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg70>=0.2: #Checking if annotator is reliable\n",
    "        if df5.annotation_70[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df5.annotation_70[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df5.annotation_70[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if pm>am and pm>uc:\n",
    "        df5.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df5.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df5.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df5.label[i]=df5.annotation_69[i] #In case of ties\n",
    "\n",
    "df5=df5.drop(columns=df5.columns.values.tolist()[1:len(df5.columns.values.tolist())-1])\n",
    "df5.to_csv(\"tw_st_5.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3503a8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n#CovidVaccine\\n#WaitForVaccine… ...</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDC Updates School Guidelines For Students Ret...</td>\n",
       "      <td>pro-mitigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who will get the first doses of a coronavirus ...</td>\n",
       "      <td>pro-mitigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDC puts in place new guidelines on masks in s...</td>\n",
       "      <td>pro-mitigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People who are fully vaccinated can travel wit...</td>\n",
       "      <td>pro-mitigation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           label\n",
       "0  \\n\\n\\n\\n\\n\\n\\n#CovidVaccine\\n#WaitForVaccine… ...         unclear\n",
       "1  CDC Updates School Guidelines For Students Ret...  pro-mitigation\n",
       "2  Who will get the first doses of a coronavirus ...  pro-mitigation\n",
       "3  CDC puts in place new guidelines on masks in s...  pro-mitigation\n",
       "4  People who are fully vaccinated can travel wit...  pro-mitigation"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6f4ba",
   "metadata": {},
   "source": [
    "### Combine All Primary Dataset File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bebed25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text            label\n",
      "0     Putin ahead of the curve. #CovidVaccine https:...          unclear\n",
      "1     No #compromise on quality of #COVIDvaccine: CM...  anti-mitigation\n",
      "2     This goes against CDC guidelines. Vaccinated p...   pro-mitigation\n",
      "3     #Twitter ;\\n\\n#sputnik \\nRussia state-affiliat...          unclear\n",
      "4     New CDC school guidelines: No masks required f...          unclear\n",
      "...                                                 ...              ...\n",
      "1795  Dr Reddy's Laboratories and Russian Direct Inv...   pro-mitigation\n",
      "1796  \"#Covishield will be commercialised once the t...   pro-mitigation\n",
      "1797  I am not, last lockdown here on RI was a compl...  anti-mitigation\n",
      "1798   https://t.co/vuf52eSRgq  Why this warning or ...          unclear\n",
      "1799  Opioid Prescribing Practices After the 2016 Re...          unclear\n",
      "\n",
      "[1794 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "joined_files = os.path.join(\"tw_st_*.csv\") #Merging the files\n",
    "  \n",
    "joined_list = glob.glob(joined_files) #A list of all joined files is returned\n",
    "  \n",
    "dfT = pd.concat(map(pd.read_csv, joined_list), ignore_index=True) #Finally all the files are joined\n",
    "dfT = dfT.drop_duplicates() # dropping duplicates\n",
    "\n",
    "print(dfT)\n",
    "dfT.to_csv(\"final_datasets/twitter_stance_combined.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5fe04",
   "metadata": {},
   "source": [
    "### ChangeOrgStance (Secondaray Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54f4ba1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.024751118823636897\n",
      "0.40907214947660675\n",
      "0.17300924079821078\n",
      "\n",
      "Average Kappa score for annotation_106 is  0.18577675715039355\n",
      "\n",
      "\n",
      "-0.024751118823636675\n",
      "0.004059362006343825\n",
      "0.03908060777749145\n",
      "\n",
      "Average Kappa score for annotation_107 is  0.0061296169867328665\n",
      "\n",
      "\n",
      "0.40907214947660686\n",
      "0.004059362006344047\n",
      "0.14084456935501088\n",
      "\n",
      "Average Kappa score for annotation_108 is  0.18465869361265394\n",
      "\n",
      "\n",
      "0.1730092407982109\n",
      "0.03908060777749167\n",
      "0.14084456935501077\n",
      "\n",
      "Average Kappa score for annotation_101 is  0.11764480597690445\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df0 = pd.read_csv (r'changeorg_stance/changeorg_stance_0.csv') #changeorg_stance_0\n",
    "df0[\"label\"]=\"\"  #Adding a column for final label\n",
    "\n",
    "df0['annotation_106'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df0['annotation_107'].fillna('missing', inplace=True)\n",
    "df0['annotation_108'].fillna('missing', inplace=True)\n",
    "df0['annotation_101'].fillna('missing', inplace=True)\n",
    "\n",
    "x106=k(df0.annotation_106, df0.annotation_107) #annotation_106\n",
    "print (x106)\n",
    "y106=k(df0.annotation_106, df0.annotation_108)\n",
    "print (y106)\n",
    "z106=k(df0.annotation_106, df0.annotation_101)\n",
    "print (z106)\n",
    "avg106=(x106+y106+z106)/3\n",
    "print('\\nAverage Kappa score for annotation_106 is ', avg106)\n",
    "print('\\n')\n",
    "\n",
    "x107=k(df0.annotation_107, df0.annotation_106) #annotation_107\n",
    "print (x107)\n",
    "y107=k(df0.annotation_107, df0.annotation_108)\n",
    "print (y107)\n",
    "z107=k(df0.annotation_107, df0.annotation_101)\n",
    "print (z107)\n",
    "avg107=(x107+y107+z107)/3\n",
    "print('\\nAverage Kappa score for annotation_107 is ', avg107)\n",
    "print('\\n')\n",
    "\n",
    "x108=k(df0.annotation_108, df0.annotation_106) #annotation_108\n",
    "print (x108)\n",
    "y108=k(df0.annotation_108, df0.annotation_107)\n",
    "print (y108)\n",
    "z108=k(df0.annotation_108, df0.annotation_101)\n",
    "print (z108)\n",
    "avg108=(x108+y108+z108)/3\n",
    "print('\\nAverage Kappa score for annotation_108 is ', avg108)\n",
    "print('\\n')\n",
    "\n",
    "x101=k(df0.annotation_101, df0.annotation_106) #annotation_101\n",
    "print (x101)\n",
    "y101=k(df0.annotation_101, df0.annotation_107)\n",
    "print (y101)\n",
    "z101=k(df0.annotation_101, df0.annotation_108)\n",
    "print (z101)\n",
    "avg101=(x101+y101+z101)/3\n",
    "print('\\nAverage Kappa score for annotation_101 is ', avg101)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "874089cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df0.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg106>=0.2: #Checking if annotator is reliable\n",
    "        if df0.annotation_106[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df0.annotation_106[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df0.annotation_106[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg107>=0.2: #Checking if annotator is reliable\n",
    "        if df0.annotation_107[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df0.annotation_107[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df0.annotation_107[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg108>=0.2: #Checking if annotator is reliable\n",
    "        if df0.annotation_108[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df0.annotation_108[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df0.annotation_108[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg101>=0.2: #Checking if annotator is reliable\n",
    "        if df0.annotation_101[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df0.annotation_101[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df0.annotation_101[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if pm>am and pm>uc:\n",
    "        df0.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df0.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df0.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df0.label[i]=df0.annotation_106[i] #In case of ties\n",
    "\n",
    "df0=df0.drop(columns=df0.columns.values.tolist()[1:len(df0.columns.values.tolist())-1])\n",
    "df0.to_csv(\"ch_st_0.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84ca9e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1c3bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2822590503466462\n",
      "0.2612227447627191\n",
      "-0.0013188101401846453\n",
      "\n",
      "Average Kappa score for annotation_73 is  0.1807209949897269\n",
      "\n",
      "\n",
      "0.2822590503466462\n",
      "0.22722342733188716\n",
      "-0.023890784982935065\n",
      "\n",
      "Average Kappa score for annotation_77 is  0.16186389756519945\n",
      "\n",
      "\n",
      "0.26122274476271923\n",
      "0.22722342733188716\n",
      "0.02783547985043633\n",
      "\n",
      "Average Kappa score for annotation_78 is  0.1720938839816809\n",
      "\n",
      "\n",
      "-0.0013188101401846453\n",
      "-0.023890784982935065\n",
      "0.027835479850436107\n",
      "\n",
      "Average Kappa score for annotation_79 is  0.0008752949091054655\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df1 = pd.read_csv (r'changeorg_stance/changeorg_stance_1.csv') #changeorg_stance_1\n",
    "df1[\"label\"]=\"\"  #Adding a column for final label\n",
    "\n",
    "df1['annotation_73'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df1['annotation_77'].fillna('missing', inplace=True)\n",
    "df1['annotation_78'].fillna('missing', inplace=True)\n",
    "df1['annotation_79'].fillna('missing', inplace=True)\n",
    "\n",
    "w73=k(df1.annotation_73, df1.annotation_77) #annotation_73\n",
    "print (w73)\n",
    "x73=k(df1.annotation_73, df1.annotation_78)\n",
    "print (x73)\n",
    "y73=k(df1.annotation_73, df1.annotation_79)\n",
    "print (y73)\n",
    "avg73=(w73+x73+y73)/3\n",
    "print('\\nAverage Kappa score for annotation_73 is ', avg73)\n",
    "print('\\n')\n",
    "\n",
    "w77=k(df1.annotation_77, df1.annotation_73) #annotation_77\n",
    "print (w77)\n",
    "x77=k(df1.annotation_77, df1.annotation_78)\n",
    "print (x77)\n",
    "y77=k(df1.annotation_77, df1.annotation_79)\n",
    "print (y77)\n",
    "avg77=(w77+x77+y77)/3\n",
    "print('\\nAverage Kappa score for annotation_77 is ', avg77)\n",
    "print('\\n')\n",
    "\n",
    "w78=k(df1.annotation_78, df1.annotation_73) #annotation_78\n",
    "print (w78)\n",
    "x78=k(df1.annotation_78, df1.annotation_77)\n",
    "print (x78)\n",
    "y78=k(df1.annotation_78, df1.annotation_79)\n",
    "print (y78)\n",
    "avg78=(w78+x78+y78)/3\n",
    "print('\\nAverage Kappa score for annotation_78 is ', avg78)\n",
    "print('\\n')\n",
    "\n",
    "w79=k(df1.annotation_79, df1.annotation_73) #annotation_79\n",
    "print (w79)\n",
    "x79=k(df1.annotation_79, df1.annotation_77)\n",
    "print (x79)\n",
    "y79=k(df1.annotation_79, df1.annotation_78)\n",
    "print (y79)\n",
    "avg79=(w79+x79+y79)/3\n",
    "print('\\nAverage Kappa score for annotation_79 is ', avg79)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b20c70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df1.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg73>=0.2: #Checking if annotator is reliable\n",
    "        if df1.annotation_73[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df1.annotation_73[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df1.annotation_73[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg77>=0.2: #Checking if annotator is reliable\n",
    "        if df1.annotation_77[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df1.annotation_77[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df1.annotation_77[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg78>=0.2: #Checking if annotator is reliable\n",
    "        if df1.annotation_78[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df1.annotation_78[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df1.annotation_78[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg79>=0.2: #Checking if annotator is reliable\n",
    "        if df1.annotation_79[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df1.annotation_79[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df1.annotation_79[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if pm>am and pm>uc:\n",
    "        df1.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df1.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df1.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df1.label[i]=df1.annotation_73[i] #In case of ties\n",
    "\n",
    "df1=df1.drop(columns=df1.columns.values.tolist()[1:len(df1.columns.values.tolist())-1])\n",
    "df1.to_csv(\"ch_st_1.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05db74ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "300d185b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4347566954415242\n",
      "0.4826065654091132\n",
      "0.49739592817860656\n",
      "\n",
      "Average Kappa score for annotation_84 is  0.4715863963430813\n",
      "\n",
      "\n",
      "0.4347566954415242\n",
      "0.5152518325845353\n",
      "0.46820547635211585\n",
      "\n",
      "Average Kappa score for annotation_85 is  0.4727380014593918\n",
      "\n",
      "\n",
      "0.4826065654091132\n",
      "0.5152518325845353\n",
      "0.48118119607259746\n",
      "\n",
      "Average Kappa score for annotation_86 is  0.493013198022082\n",
      "\n",
      "\n",
      "0.49739592817860656\n",
      "0.46820547635211585\n",
      "0.48118119607259746\n",
      "\n",
      "Average Kappa score for annotation_87 is  0.48226086686777325\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df2 = pd.read_csv (r'changeorg_stance/changeorg_stance_2.csv') #changeorg_stance_2\n",
    "df2[\"label\"]=\"\" #Adding a column for final label\n",
    "\n",
    "df2['annotation_84'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df2['annotation_85'].fillna('missing', inplace=True)\n",
    "df2['annotation_86'].fillna('missing', inplace=True)\n",
    "df2['annotation_87'].fillna('missing', inplace=True)\n",
    "\n",
    "x84=k(df2.annotation_84, df2.annotation_85) #annotation_84\n",
    "print (x84)\n",
    "y84=k(df2.annotation_84, df2.annotation_86)\n",
    "print (y84)\n",
    "z84=k(df2.annotation_84, df2.annotation_87)\n",
    "print (z84)\n",
    "avg84=(x84+y84+z84)/3\n",
    "print('\\nAverage Kappa score for annotation_84 is ', avg84)\n",
    "print('\\n')\n",
    "\n",
    "x85=k(df2.annotation_85, df2.annotation_84) #annotation_85\n",
    "print (x85)\n",
    "y85=k(df2.annotation_85, df2.annotation_86)\n",
    "print (y85)\n",
    "z85=k(df2.annotation_85, df2.annotation_87)\n",
    "print (z85)\n",
    "avg85=(x85+y85+z85)/3\n",
    "print('\\nAverage Kappa score for annotation_85 is ', avg85)\n",
    "print('\\n')\n",
    "\n",
    "x86=k(df2.annotation_86, df2.annotation_84) #annotation_86\n",
    "print (x86)\n",
    "y86=k(df2.annotation_86, df2.annotation_85)\n",
    "print (y86)\n",
    "z86=k(df2.annotation_86, df2.annotation_87)\n",
    "print (z86)\n",
    "avg86=(x86+y86+z86)/3\n",
    "print('\\nAverage Kappa score for annotation_86 is ', avg86)\n",
    "print('\\n')\n",
    "\n",
    "x87=k(df2.annotation_87, df2.annotation_84) #annotation_87\n",
    "print (x87)\n",
    "y87=k(df2.annotation_87, df2.annotation_85)\n",
    "print (y87)\n",
    "z87=k(df2.annotation_87, df2.annotation_86)\n",
    "print (z87)\n",
    "avg87=(x87+y87+z87)/3\n",
    "print('\\nAverage Kappa score for annotation_87 is ', avg87)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78be92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df2.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg84>=0.2: #Checking if annotator is reliable\n",
    "        if df2.annotation_84[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df2.annotation_84[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df2.annotation_84[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg85>=0.2: #Checking if annotator is reliable\n",
    "        if df2.annotation_85[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df2.annotation_85[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df2.annotation_85[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg86>=0.2: #Checking if annotator is reliable\n",
    "        if df2.annotation_86[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df2.annotation_86[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df2.annotation_86[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg87>=0.2: #Checking if annotator is reliable\n",
    "        if df2.annotation_87[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df2.annotation_87[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df2.annotation_87[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if pm>am and pm>uc:\n",
    "        df2.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df2.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df2.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df2.label[i]=df2.annotation_86[i] #In case of ties\n",
    "\n",
    "df2=df2.drop(columns=df2.columns.values.tolist()[1:len(df2.columns.values.tolist())-1])\n",
    "df2.to_csv(\"ch_st_2.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a33be658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b141d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0755355129650509\n",
      "0.4730062068157863\n",
      "0.40713652482269513\n",
      "\n",
      "Average Kappa score for annotation_97 is  0.3185594148678441\n",
      "\n",
      "\n",
      "0.07553551296505079\n",
      "0.007908839173655702\n",
      "0.004578936890304641\n",
      "\n",
      "Average Kappa score for annotation_101 is  0.02934109634300371\n",
      "\n",
      "\n",
      "0.4730062068157863\n",
      "0.007908839173655702\n",
      "0.36008676789587857\n",
      "\n",
      "Average Kappa score for annotation_102 is  0.2803339379617735\n",
      "\n",
      "\n",
      "0.40713652482269513\n",
      "0.00457893689030453\n",
      "0.36008676789587857\n",
      "\n",
      "Average Kappa score for annotation_14 is  0.2572674098696261\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df3 = pd.read_csv (r'changeorg_stance/changeorg_stance_3.csv') #changeorg_stance_3\n",
    "df3[\"label\"]=\"\" #Adding a column for final label\n",
    "\n",
    "df3['annotation_97'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df3['annotation_101'].fillna('missing', inplace=True)\n",
    "df3['annotation_102'].fillna('missing', inplace=True)\n",
    "df3['annotation_14'].fillna('missing', inplace=True)\n",
    "\n",
    "x97=k(df3.annotation_97, df3.annotation_101) #annotation_97\n",
    "print (x97)\n",
    "y97=k(df3.annotation_97, df3.annotation_102)\n",
    "print (y97)\n",
    "z97=k(df3.annotation_97, df3.annotation_14)\n",
    "print (z97)\n",
    "avg97=(x97+y97+z97)/3\n",
    "print('\\nAverage Kappa score for annotation_97 is ', avg97)\n",
    "print('\\n')\n",
    "\n",
    "x101=k(df3.annotation_101, df3.annotation_97) #annotation_101\n",
    "print (x101)\n",
    "y101=k(df3.annotation_101, df3.annotation_102)\n",
    "print (y101)\n",
    "z101=k(df3.annotation_101, df3.annotation_14)\n",
    "print (z101)\n",
    "avg101=(x101+y101+z101)/3\n",
    "print('\\nAverage Kappa score for annotation_101 is ', avg101)\n",
    "print('\\n')\n",
    "\n",
    "x102=k(df3.annotation_102, df3.annotation_97) #annotation_102\n",
    "print (x102)\n",
    "y102=k(df3.annotation_102, df3.annotation_101)\n",
    "print (y102)\n",
    "z102=k(df3.annotation_102, df3.annotation_14)\n",
    "print (z102)\n",
    "avg102=(x102+y102+z102)/3\n",
    "print('\\nAverage Kappa score for annotation_102 is ', avg102)\n",
    "print('\\n')\n",
    "\n",
    "x14=k(df3.annotation_14, df3.annotation_97) #annotation_14\n",
    "print (x14)\n",
    "y14=k(df3.annotation_14, df3.annotation_101)\n",
    "print (y14)\n",
    "z14=k(df3.annotation_14, df3.annotation_102)\n",
    "print (z14)\n",
    "avg14=(x14+y14+z14)/3\n",
    "print('\\nAverage Kappa score for annotation_14 is ', avg14)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fdd73290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df3.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg97>=0.2: #Checking if annotator is reliable\n",
    "        if df3.annotation_97[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df3.annotation_97[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df3.annotation_97[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg101>=0.2: #Checking if annotator is reliable\n",
    "        if df3.annotation_101[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df3.annotation_101[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df3.annotation_101[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg102>=0.2: #Checking if annotator is reliable\n",
    "        if df3.annotation_102[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df3.annotation_102[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df3.annotation_102[i]=='unclear':\n",
    "            uc=uc+1\n",
    "            \n",
    "    if avg14>=0.2: #Checking if annotator is reliable\n",
    "        if df3.annotation_14[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df3.annotation_14[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df3.annotation_14[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if pm>am and pm>uc:\n",
    "        df3.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df3.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df3.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df3.label[i]=df3.annotation_97[i] #In case of ties\n",
    "\n",
    "df3=df3.drop(columns=df3.columns.values.tolist()[1:len(df3.columns.values.tolist())-1])\n",
    "df3.to_csv(\"ch_st_3.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3840be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8735c753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056453918734313935\n",
      "0.047657317367194585\n",
      "-0.055845064945166056\n",
      "\n",
      "Average Kappa score for annotation_92 is  0.016088723718780822\n",
      "\n",
      "\n",
      "0.056453918734313935\n",
      "0.4421295499156306\n",
      "0.2881736927550711\n",
      "\n",
      "Average Kappa score for annotation_93 is  0.2622523871350052\n",
      "\n",
      "\n",
      "0.04765731736719436\n",
      "0.4421295499156306\n",
      "0.3735599078341014\n",
      "\n",
      "Average Kappa score for annotation_94 is  0.2877822583723088\n",
      "\n",
      "\n",
      "-0.055845064945166056\n",
      "0.288173692755071\n",
      "0.3735599078341014\n",
      "\n",
      "Average Kappa score for annotation_95 is  0.20196284521466878\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "df4 = pd.read_csv (r'changeorg_stance/changeorg_stance_4.csv') #changeorg_stance_4\n",
    "df4[\"label\"]=\"\" #Adding a column for final label\n",
    "\n",
    "df4['annotation_92'].fillna('missing', inplace=True) #Handling empty cells in the data file\n",
    "df4['annotation_93'].fillna('missing', inplace=True)\n",
    "df4['annotation_94'].fillna('missing', inplace=True)\n",
    "df4['annotation_95'].fillna('missing', inplace=True)\n",
    "\n",
    "x92=k(df4.annotation_92, df4.annotation_93) #annotation_92\n",
    "print (x92)\n",
    "y92=k(df4.annotation_92, df4.annotation_94)\n",
    "print (y92)\n",
    "z92=k(df4.annotation_92, df4.annotation_95)\n",
    "print (z92)\n",
    "avg92=(x92+y92+z92)/3\n",
    "print('\\nAverage Kappa score for annotation_92 is ', avg92)\n",
    "print('\\n')\n",
    "\n",
    "x93=k(df4.annotation_93, df4.annotation_92) #annotation_93\n",
    "print (x93)\n",
    "y93=k(df4.annotation_93, df4.annotation_94)\n",
    "print (y93)\n",
    "z93=k(df4.annotation_93, df4.annotation_95)\n",
    "print (z93)\n",
    "avg93=(x93+y93+z93)/3\n",
    "print('\\nAverage Kappa score for annotation_93 is ', avg93)\n",
    "print('\\n')\n",
    "\n",
    "x94=k(df4.annotation_94, df4.annotation_92) #annotation_94\n",
    "print (x94)\n",
    "y94=k(df4.annotation_94, df4.annotation_93)\n",
    "print (y94)\n",
    "z94=k(df4.annotation_94, df4.annotation_95)\n",
    "print (z94)\n",
    "avg94=(x94+y94+z94)/3\n",
    "print('\\nAverage Kappa score for annotation_94 is ', avg94)\n",
    "print('\\n')\n",
    "\n",
    "x95=k(df4.annotation_95, df4.annotation_92) #annotation_95\n",
    "print (x95)\n",
    "y95=k(df4.annotation_95, df4.annotation_93)\n",
    "print (y95)\n",
    "z95=k(df4.annotation_95, df4.annotation_94)\n",
    "print (z95)\n",
    "avg95=(x95+y95+z95)/3\n",
    "print('\\nAverage Kappa score for annotation_95 is ', avg95)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1ddc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "for i in df4.index:\n",
    "    pm=0\n",
    "    am=0\n",
    "    uc=0\n",
    "    \n",
    "    if avg92>=0.2: #Checking if annotator is reliable\n",
    "        if df4.annotation_92[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df4.annotation_92[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df4.annotation_92[i]=='unclear':\n",
    "            uc=uc+1\n",
    "            \n",
    "    if avg93>=0.2: #Checking if annotator is reliable\n",
    "        if df4.annotation_93[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df4.annotation_93[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df4.annotation_93[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg94>=0.2: #Checking if annotator is reliable\n",
    "        if df4.annotation_94[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df4.annotation_94[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df4.annotation_94[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if avg95>=0.2: #Checking if annotator is reliable\n",
    "        if df4.annotation_95[i]=='pro-mitigation':\n",
    "            pm=pm+1\n",
    "        elif df4.annotation_95[i]=='anti-mitigation':\n",
    "            am=am+1\n",
    "        elif df4.annotation_95[i]=='unclear':\n",
    "            uc=uc+1\n",
    "\n",
    "    if pm>am and pm>uc:\n",
    "        df4.label[i]=\"pro-mitigation\"\n",
    "    elif am>pm and am>uc:\n",
    "        df4.label[i]=\"anti-mitigation\"\n",
    "    elif uc>pm and uc>am:\n",
    "        df4.label[i]=\"unclear\"\n",
    "    else:\n",
    "        df4.label[i]=df4.annotation_94[i] #In case of ties\n",
    "\n",
    "df4=df4.drop(columns=df4.columns.values.tolist()[1:len(df4.columns.values.tolist())-1])\n",
    "df4.to_csv(\"ch_st_4.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfa64ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634c01a1",
   "metadata": {},
   "source": [
    "### Combine All Secondary Dataset File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f42a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text            label\n",
      "0     Shut down all Visalia Unified School District ...   pro-mitigation\n",
      "1     Allow Fall Advantage participants to arrive fo...          unclear\n",
      "2          Opt-In and Implement AB 626 in Orange County          unclear\n",
      "3     PM Modi: Tell Indian Men to Do an Equal Share ...          unclear\n",
      "4            No More Live Markets - make the difference   pro-mitigation\n",
      "...                                                 ...              ...\n",
      "1495        Shut Down All B​.​C Schools Due To Covid-19   pro-mitigation\n",
      "1496  COVID-19 Single parents and guardians of minor...  anti-mitigation\n",
      "1497  Slow/Stop Spread of COVID-19 in Milpitas (@WeA...   pro-mitigation\n",
      "1498  Open the QLD border to postcodes that have no ...  anti-mitigation\n",
      "1499  COVID-19: Please allow parents to keep school ...   pro-mitigation\n",
      "\n",
      "[1500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "joined_files = os.path.join(\"ch_st_*.csv\") #Merging the files\n",
    "  \n",
    "joined_list = glob.glob(joined_files) #A list of all joined files is returned\n",
    "  \n",
    "dfC = pd.concat(map(pd.read_csv, joined_list), ignore_index=True) #Finally all the files are joined\n",
    "dfC = dfC.drop_duplicates() # dropping duplicates\n",
    "\n",
    "print(dfC)\n",
    "dfC.to_csv(\"changeorg_stance_combined.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eccdc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
